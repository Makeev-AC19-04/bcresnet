{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapok/miniconda3/envs/bcresnet/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:\t {'alyona': 1, 'filler': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapok/miniconda3/envs/bcresnet/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370120218/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "path_to_import = str(Path().resolve() / \"../\" )\n",
    "if path_to_import not in sys.path:\n",
    "    sys.path.append(path_to_import)\n",
    "\n",
    "from bcresnet import BCResNets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import wave\n",
    "import noisereduce as nr\n",
    "import pyaudio\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils import Padding, Preprocess, SpeechCommand, SplitDataset, LogMel, spec_augment\n",
    "\n",
    "THRESHOLD = 0.85\n",
    "gpu = 1\n",
    "device = torch.device(\"cuda:%d\" % gpu if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCResNets(\n",
       "  (cnn_head): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(2, 1), padding=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (BCBlocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=[1, 0], dilation=[1, 1], groups=8, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=[0, 1], dilation=[1, 1], groups=8, bias=False)\n",
       "              (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=[1, 0], dilation=[1, 1], groups=8, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 8, kernel_size=(1, 3), stride=(1, 1), padding=[0, 1], dilation=[1, 1], groups=8, bias=False)\n",
       "              (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(8, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(12, 12, kernel_size=(3, 1), stride=(2, 1), padding=[1, 0], dilation=[1, 1], groups=12, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(12, 12, kernel_size=(1, 3), stride=(1, 1), padding=[0, 2], dilation=[1, 2], groups=12, bias=False)\n",
       "              (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(12, 12, kernel_size=(3, 1), stride=(1, 1), padding=[1, 0], dilation=[1, 1], groups=12, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(12, 12, kernel_size=(1, 3), stride=(1, 1), padding=[0, 2], dilation=[1, 2], groups=12, bias=False)\n",
       "              (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 1), stride=(2, 1), padding=[1, 0], dilation=[1, 1], groups=16, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=[0, 4], dilation=[1, 4], groups=16, bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=[1, 0], dilation=[1, 1], groups=16, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=[0, 4], dilation=[1, 4], groups=16, bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=[1, 0], dilation=[1, 1], groups=16, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=[0, 4], dilation=[1, 4], groups=16, bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=[1, 0], dilation=[1, 1], groups=16, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=[0, 4], dilation=[1, 4], groups=16, bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(16, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=[1, 0], dilation=[1, 1], groups=20, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=[0, 8], dilation=[1, 8], groups=20, bias=False)\n",
       "              (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=[1, 0], dilation=[1, 1], groups=20, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=[0, 8], dilation=[1, 8], groups=20, bias=False)\n",
       "              (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=[1, 0], dilation=[1, 1], groups=20, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=[0, 8], dilation=[1, 8], groups=20, bias=False)\n",
       "              (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BCResBlock(\n",
       "        (f2): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(20, 20, kernel_size=(3, 1), stride=(1, 1), padding=[1, 0], dilation=[1, 1], groups=20, bias=False)\n",
       "              (1): SubSpectralNorm(\n",
       "                (ssnorm): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avg_gpool): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (f1): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2d(20, 20, kernel_size=(1, 3), stride=(1, 1), padding=[0, 8], dilation=[1, 8], groups=20, bias=False)\n",
       "              (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): Dropout2d(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1), padding=(0, 2), groups=20, bias=False)\n",
       "    (1): Conv2d(20, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (5): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BCResNets(int(1 * 8)).to(device)\n",
    "#model.load_state_dict(torch.load(\"../models/go_model.pth\"))\n",
    "model.load_state_dict(torch.load(\"../models/bed_model.pth\"))\n",
    "#model.load_state_dict(torch.load(\"../models/model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прослушивание сигнала и идентификация ключевого слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapok/miniconda3/envs/bcresnet/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filler\n",
      "Filler\n",
      "Filler\n",
      "Filler\n",
      "Filler\n",
      "Filler\n",
      "Keyword\n",
      "Filler\n",
      "Filler\n",
      "Keyword\n",
      "Filler\n",
      "Filler\n",
      "Keyword\n",
      "Filler\n",
      "Filler\n",
      "Filler\n",
      "Filler\n",
      "Filler\n",
      "Filler\n",
      "Filler\n",
      "Filler\n",
      "Keyword\n",
      "Filler\n",
      "Filler\n",
      "Keyword\n",
      "Filler\n"
     ]
    }
   ],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 1.2\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "def process_sample(sample):\n",
    "    sample = torch.clamp(sample, -1.0, 1.0)\n",
    "    SR = 16000\n",
    "    hop_length=160\n",
    "    win_length=480\n",
    "    n_fft=512\n",
    "    n_mels=40\n",
    "    feature = LogMel(\n",
    "                device,\n",
    "                sample_rate=SR,\n",
    "                hop_length=hop_length,\n",
    "                win_length=win_length,\n",
    "                n_fft=n_fft,\n",
    "                n_mels=n_mels,\n",
    "            )\n",
    "    sample = feature(sample)  \n",
    "    sample = spec_augment(sample)\n",
    "    return sample\n",
    "\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Recording...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        \n",
    "        # Process audio data within the recording loop\n",
    "        sample = torch.zeros(1, int(RATE * RECORD_SECONDS))\n",
    "        for i in range(int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            audio_tensor = torch.from_numpy(np.frombuffer(data, dtype=np.int16) / 32767.0) \n",
    "            sample[0, i*CHUNK:(i+1)*CHUNK] = audio_tensor\n",
    "\n",
    "        #print(sample.shape)\n",
    "        #print(\"Finished recording.\")\n",
    "\n",
    "        # Process the audio tensor with feature extraction and classification\n",
    "        sample = process_sample(sample)\n",
    "        sample = sample.to(device)\n",
    "\n",
    "        outputs = model(sample.unsqueeze(0))\n",
    "        predictions = F.softmax(outputs)\n",
    "\n",
    "        #print(predictions)\n",
    "\n",
    "        if predictions[0][1].item() > 0.99:\n",
    "            print(\"Keyword\")\n",
    "        else:\n",
    "            pass\n",
    "            print(\"Filler\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Записать сигнал в .wav файл и отдельно его распознать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_wav(filepath:str):\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 16000\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 1.0\n",
    "    WAVE_OUTPUT_FILENAME = filepath\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    waveFile = wave.open(WAVE_OUTPUT_FILENAME, \"wb\")\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b\"\".join(frames))\n",
    "    waveFile.close()\n",
    "\n",
    "def record_wav_nr(filepath:str, stationary:bool):\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 16000\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 1.0\n",
    "    WAVE_OUTPUT_FILENAME = filepath\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Combine audio data from frames\n",
    "    audio_signal = np.frombuffer(b\"\".join(frames), dtype=np.int16)\n",
    "    # Perform noise reduction using Noisereduce Library\n",
    "    \n",
    "    reduced_noise = nr.reduce_noise(y=audio_signal, sr=RATE, stationary=stationary)\n",
    "\n",
    "    waveFile = wave.open(WAVE_OUTPUT_FILENAME, \"wb\")\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(reduced_noise.astype(np.int16).tobytes())\n",
    "    waveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wav(sample: str):\n",
    "    sample, _ = torchaudio.load(sample)\n",
    "\n",
    "    sample = torch.cat([sample, torch.zeros([sample.shape[0], 16000])], dim=-1)\n",
    "\n",
    "    sample = torch.clamp(sample, -1.0, 1.0)\n",
    "    SR = 16000\n",
    "    hop_length=160\n",
    "    win_length=480\n",
    "    n_fft=512\n",
    "    n_mels=40\n",
    "    feature = LogMel(\n",
    "                device,\n",
    "                sample_rate=SR,\n",
    "                hop_length=hop_length,\n",
    "                win_length=win_length,\n",
    "                n_fft=n_fft,\n",
    "                n_mels=n_mels,\n",
    "            )\n",
    "    sample = feature(sample)  \n",
    "    sample = spec_augment(sample)\n",
    "    sample = sample.to(device)\n",
    "\n",
    "    outputs = model(sample.unsqueeze(0))\n",
    "    predictions = F.softmax(outputs)\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "    if predictions[0][1].item() > THRESHOLD:\n",
    "        return \"Keyword\"\n",
    "    else:\n",
    "        return \"Filler\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эксперименты с шумоподавлением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "tensor([[0.9271, 0.0729]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapok/miniconda3/envs/bcresnet/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Filler'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_wav_nr(\"output_non_stationary_nr.wav\", False)\n",
    "predict_wav(\"output_non_stationary_nr.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "tensor([[0.2089, 0.7911]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapok/miniconda3/envs/bcresnet/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Filler'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_wav_nr(\"output_stationary_nr.wav\", True)\n",
    "predict_wav(\"output_stationary_nr.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "tensor([[0.2531, 0.7469]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapok/miniconda3/envs/bcresnet/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Filler'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_wav_nr(\"output.wav\")\n",
    "predict_wav(\"output.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Записать сигнал и сразу его распознать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "tensor([[0.0021, 0.9979]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapok/miniconda3/envs/bcresnet/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 1.2\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "def process_sample(sample):\n",
    "    sample = torch.clamp(sample, -1.0, 1.0)\n",
    "    SR = 16000\n",
    "    hop_length=160\n",
    "    win_length=480\n",
    "    n_fft=512\n",
    "    n_mels=40\n",
    "    feature = LogMel(\n",
    "                device,\n",
    "                sample_rate=SR,\n",
    "                hop_length=hop_length,\n",
    "                win_length=win_length,\n",
    "                n_fft=n_fft,\n",
    "                n_mels=n_mels,\n",
    "            )\n",
    "    sample = feature(sample)  \n",
    "    sample = spec_augment(sample)\n",
    "    return sample\n",
    "\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Recording...\")\n",
    "\n",
    "# Process audio data within the recording loop\n",
    "sample = torch.zeros(1, int(RATE * RECORD_SECONDS))\n",
    "for i in range(int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    audio_tensor = torch.from_numpy(np.frombuffer(data, dtype=np.int16) / 32767.0) \n",
    "    sample[0, i*CHUNK:(i+1)*CHUNK] = audio_tensor\n",
    "\n",
    "print(\"Finished recording.\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "# Process the audio tensor with feature extraction and classification\n",
    "sample = process_sample(sample)\n",
    "sample = sample.to(device)\n",
    "\n",
    "outputs = model(sample.unsqueeze(0))\n",
    "predictions = F.softmax(outputs)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "if predictions[0][1].item() > 0.99:\n",
    "    print(\"Keyword\")\n",
    "else:\n",
    "    print(\"Filler\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Записать 100 сигналов по секунде, например, для записи шума"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording...\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "for i in range(201, 251):\n",
    "    record_wav(f\"records/output_{i}.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Keywords---\n",
      "0ea0e2f4_nohash_0.wav\n",
      "tensor([[0.1045, 0.8955]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "0c40e715_nohash_0.wav\n",
      "tensor([[0.0326, 0.9674]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "2d82a556_nohash_0.wav\n",
      "tensor([[0.0725, 0.9275]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "1cb788bc_nohash_1.wav\n",
      "tensor([[0.0194, 0.9806]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "1acc97de_nohash_0.wav\n",
      "tensor([[0.0264, 0.9736]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "0cb74144_nohash_0.wav\n",
      "tensor([[0.4991, 0.5009]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "2c6d3924_nohash_0.wav\n",
      "tensor([[0.0033, 0.9967]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "1b4c9b89_nohash_0.wav\n",
      "tensor([[0.0170, 0.9830]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "1cb788bc_nohash_0.wav\n",
      "tensor([[0.1208, 0.8792]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "0ea0e2f4_nohash_1.wav\n",
      "tensor([[0.0289, 0.9711]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "---Fillers---\n",
      "10587.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapok/miniconda3/envs/bcresnet/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9960, 0.0040]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "0a5636ca_nohash_0.wav\n",
      "tensor([[0.1131, 0.8869]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "10547.wav\n",
      "tensor([[0.9950, 0.0050]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "10546.wav\n",
      "tensor([[0.9950, 0.0050]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "10745.wav\n",
      "tensor([[0.9952, 0.0048]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "10551.wav\n",
      "tensor([[0.9939, 0.0061]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "0b09edd3_nohash_0.wav\n",
      "tensor([[0.3080, 0.6920]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "10431.wav\n",
      "tensor([[0.9954, 0.0046]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "10742.wav\n",
      "tensor([[0.9939, 0.0061]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "10394.wav\n",
      "tensor([[0.9945, 0.0055]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "10585.wav\n",
      "tensor([[0.9952, 0.0048]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "0a2b400e_nohash_3.wav\n",
      "tensor([[0.4602, 0.5398]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "10618.wav\n",
      "tensor([[0.9928, 0.0072]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = '../data/bed/final_test/bed/'\n",
    "files = os.listdir(directory)\n",
    "print(\"---Keywords---\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "    print(predict_wav(directory + file))\n",
    "\n",
    "print(\"---Fillers---\")\n",
    "directory = '../data/bed/final_test/filler/'\n",
    "files = os.listdir(directory)\n",
    "for file in files:\n",
    "    print(file)\n",
    "    print(predict_wav(directory + file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Записывать сигнал и распознавать ключевое слово в потоковом режиме "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Iteration: 1, sample: tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0462, -0.0603, -0.0490]]), time to record and predict: 0.1319291591644287\n",
      "tensor([[0.2381, 0.7619]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapok/miniconda3/envs/bcresnet/lib/python3.6/site-packages/ipykernel_launcher.py:61: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2, sample: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1284, 0.1263, 0.1300]]), time to record and predict: 0.12501144409179688\n",
      "tensor([[0.1135, 0.8865]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 3, sample: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1008, 0.0947, 0.0908]]), time to record and predict: 0.1248788833618164\n",
      "tensor([[0.0473, 0.9527]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 4, sample: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0033, 0.0056, 0.0147]]), time to record and predict: 0.13573336601257324\n",
      "tensor([[0.0190, 0.9810]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 5, sample: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0186, 0.0266, 0.0376]]), time to record and predict: 0.020361900329589844\n",
      "tensor([[0.0125, 0.9875]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 6, sample: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1136, 0.1224, 0.1243]]), time to record and predict: 0.1492922306060791\n",
      "tensor([[0.0036, 0.9964]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 7, sample: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0147, 0.0233, 0.0236]]), time to record and predict: 0.11770486831665039\n",
      "tensor([[0.0026, 0.9974]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 8, sample: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0828, 0.0841, 0.0895]]), time to record and predict: 0.02797389030456543\n",
      "tensor([[0.0057, 0.9943]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 9, sample: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0518, 0.0578, 0.0642]]), time to record and predict: 0.13960909843444824\n",
      "tensor([[0.0354, 0.9646]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 10, sample: tensor([[-0.0220, -0.0359, -0.0376,  ...,  0.0191,  0.0175,  0.0110]]), time to record and predict: 0.12158632278442383\n",
      "tensor([[0.3475, 0.6525]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 11, sample: tensor([[-0.0372, -0.0313, -0.0240,  ..., -0.0464, -0.0443, -0.0457]]), time to record and predict: 0.016268253326416016\n",
      "tensor([[0.2953, 0.7047]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 12, sample: tensor([[0.1356, 0.1304, 0.1259,  ..., 0.1819, 0.1747, 0.1590]]), time to record and predict: 0.11009883880615234\n",
      "tensor([[0.2866, 0.7134]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 13, sample: tensor([[0.0899, 0.0896, 0.0879,  ..., 0.0543, 0.0598, 0.0629]]), time to record and predict: 0.1249704360961914\n",
      "tensor([[0.1899, 0.8101]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 14, sample: tensor([[ 0.0215,  0.0226,  0.0189,  ..., -0.0405, -0.0396, -0.0436]]), time to record and predict: 0.12795090675354004\n",
      "tensor([[0.1407, 0.8593]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 15, sample: tensor([[ 0.0420,  0.0456,  0.0481,  ..., -0.0049, -0.0062, -0.0056]]), time to record and predict: 0.12717294692993164\n",
      "tensor([[0.1686, 0.8314]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 16, sample: tensor([[0.1209, 0.1270, 0.1267,  ..., 0.1060, 0.1094, 0.1119]]), time to record and predict: 0.02090740203857422\n",
      "tensor([[0.1352, 0.8648]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 17, sample: tensor([[0.0143, 0.0066, 0.0090,  ..., 0.0902, 0.0813, 0.0832]]), time to record and predict: 0.14304685592651367\n",
      "tensor([[0.0533, 0.9467]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 18, sample: tensor([[0.0849, 0.0847, 0.0912,  ..., 0.0082, 0.0049, 0.0099]]), time to record and predict: 0.12419247627258301\n",
      "tensor([[0.0503, 0.9497]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 19, sample: tensor([[0.0614, 0.0606, 0.0636,  ..., 0.0063, 0.0081, 0.0061]]), time to record and predict: 0.015817880630493164\n",
      "tensor([[0.0536, 0.9464]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 20, sample: tensor([[ 0.0050, -0.0031, -0.0077,  ...,  0.0790,  0.0830,  0.0836]]), time to record and predict: 0.10989189147949219\n",
      "tensor([[0.0489, 0.9511]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 21, sample: tensor([[-0.0533, -0.0595, -0.0608,  ...,  0.0642,  0.0688,  0.0658]]), time to record and predict: 0.17411065101623535\n",
      "tensor([[0.0591, 0.9409]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 22, sample: tensor([[ 0.1524,  0.1518,  0.1547,  ..., -0.0003,  0.0077,  0.0088]]), time to record and predict: 0.022551774978637695\n",
      "tensor([[0.0823, 0.9177]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 23, sample: tensor([[0.0624, 0.0573, 0.0552,  ..., 0.0263, 0.0274, 0.0286]]), time to record and predict: 0.13328862190246582\n",
      "tensor([[0.1613, 0.8387]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 24, sample: tensor([[-0.0486, -0.0538, -0.0553,  ..., -0.0238, -0.0164, -0.0095]]), time to record and predict: 0.1253948211669922\n",
      "tensor([[0.1396, 0.8604]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 25, sample: tensor([[-0.0089, -0.0155, -0.0102,  ...,  0.1608,  0.1543,  0.1572]]), time to record and predict: 0.02552032470703125\n",
      "tensor([[0.1435, 0.8565]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 26, sample: tensor([[0.1213, 0.1265, 0.1290,  ..., 0.0491, 0.0465, 0.0497]]), time to record and predict: 0.1388399600982666\n",
      "tensor([[0.1591, 0.8409]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 27, sample: tensor([[ 0.0896,  0.0921,  0.0923,  ..., -0.0396, -0.0400, -0.0398]]), time to record and predict: 0.12709307670593262\n",
      "tensor([[0.2138, 0.7862]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 28, sample: tensor([[0.0119, 0.0144, 0.0161,  ..., 0.0475, 0.0186, 0.0027]]), time to record and predict: 0.013972997665405273\n",
      "tensor([[0.2414, 0.7586]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 29, sample: tensor([[0.0009, 0.0009, 0.0077,  ..., 0.1152, 0.0712, 0.0546]]), time to record and predict: 0.10716533660888672\n",
      "tensor([[0.0337, 0.9663]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 30, sample: tensor([[0.0848, 0.0840, 0.0852,  ..., 0.0385, 0.1916, 0.1511]]), time to record and predict: 0.1275768280029297\n",
      "tensor([[0.0489, 0.9511]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 31, sample: tensor([[0.0646, 0.0765, 0.0784,  ..., 0.0105, 0.0273, 0.0178]]), time to record and predict: 0.12492799758911133\n",
      "tensor([[0.0482, 0.9518]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 32, sample: tensor([[ 0.0020, -0.0070, -0.0109,  ..., -0.3713, -0.0176,  0.3502]]), time to record and predict: 0.12581396102905273\n",
      "tensor([[0.1290, 0.8710]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 33, sample: tensor([[0.0350, 0.0462, 0.0524,  ..., 0.1000, 0.0498, 0.1518]]), time to record and predict: 0.016117334365844727\n",
      "tensor([[0.2821, 0.7179]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 34, sample: tensor([[-0.0077, -0.0020,  0.0049,  ..., -0.0341, -0.3077, -0.2112]]), time to record and predict: 0.1082460880279541\n",
      "tensor([[0.4834, 0.5166]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 35, sample: tensor([[0.1561, 0.1476, 0.1476,  ..., 0.1525, 0.3619, 0.5375]]), time to record and predict: 0.13103795051574707\n",
      "tensor([[0.6750, 0.3250]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 36, sample: tensor([[ 0.0537,  0.0555,  0.0602,  ..., -0.0064,  0.0071,  0.1021]]), time to record and predict: 0.12208032608032227\n",
      "tensor([[0.8671, 0.1329]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 37, sample: tensor([[-0.0414, -0.0385, -0.0372,  ...,  0.2972,  0.4596,  0.0219]]), time to record and predict: 0.015580177307128906\n",
      "tensor([[0.9737, 0.0263]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 38, sample: tensor([[0.0227, 0.0766, 0.0821,  ..., 0.4075, 0.2065, 0.0470]]), time to record and predict: 0.11144351959228516\n",
      "tensor([[0.9865, 0.0135]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 39, sample: tensor([[0.0258, 0.0528, 0.2048,  ..., 0.1351, 0.2496, 0.7704]]), time to record and predict: 0.12637901306152344\n",
      "tensor([[0.9690, 0.0310]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 40, sample: tensor([[ 0.0279, -0.0392,  0.0354,  ...,  0.4907,  0.4212,  0.1562]]), time to record and predict: 0.12580370903015137\n",
      "tensor([[0.9215, 0.0785]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 41, sample: tensor([[ 0.0989,  0.1987,  0.2019,  ..., -0.3078, -0.2700,  0.0920]]), time to record and predict: 0.1308460235595703\n",
      "tensor([[0.9572, 0.0428]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 42, sample: tensor([[ 0.2311,  0.0729, -0.0222,  ...,  0.5172,  0.0587, -0.2416]]), time to record and predict: 0.01780223846435547\n",
      "tensor([[0.4376, 0.5624]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 43, sample: tensor([[ 0.0684,  0.0077,  0.0460,  ...,  0.1264,  0.0046, -0.1225]]), time to record and predict: 0.14143943786621094\n",
      "tensor([[0.3996, 0.6004]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 44, sample: tensor([[0.1995, 0.3231, 0.0421,  ..., 0.2842, 0.3260, 0.1722]]), time to record and predict: 0.1296389102935791\n",
      "tensor([[0.4758, 0.5242]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 45, sample: tensor([[ 0.0651, -0.2412, -0.1628,  ..., -0.0278,  0.2406,  0.2453]]), time to record and predict: 0.015740394592285156\n",
      "tensor([[0.3546, 0.6454]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 46, sample: tensor([[ 0.1825,  0.1216, -0.0457,  ..., -0.2380, -0.1089,  0.0168]]), time to record and predict: 0.10971927642822266\n",
      "tensor([[0.3024, 0.6976]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 47, sample: tensor([[-0.2490, -0.4748, -0.5327,  ...,  0.2848, -0.4178, -0.2260]]), time to record and predict: 0.12186765670776367\n",
      "tensor([[0.1308, 0.8692]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 48, sample: tensor([[-0.0233,  0.1690,  0.3909,  ..., -0.3316, -0.2494,  0.0844]]), time to record and predict: 0.13428044319152832\n",
      "tensor([[0.1072, 0.8928]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 49, sample: tensor([[ 0.5433, -0.1717, -0.3873,  ...,  0.2061,  0.1480, -0.2436]]), time to record and predict: 0.02387237548828125\n",
      "tensor([[0.1234, 0.8766]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 50, sample: tensor([[-0.0062,  0.0799,  0.5223,  ...,  0.3066,  0.2394,  0.2510]]), time to record and predict: 0.1370382308959961\n",
      "tensor([[0.1550, 0.8450]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 51, sample: tensor([[ 0.0332,  0.1971,  0.7300,  ..., -0.2086,  0.2452,  0.2961]]), time to record and predict: 0.12390637397766113\n",
      "tensor([[0.2314, 0.7686]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 52, sample: tensor([[-0.1773,  0.1535,  0.2709,  ...,  0.0314,  0.0018,  0.0263]]), time to record and predict: 0.014853477478027344\n",
      "tensor([[0.4332, 0.5668]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 53, sample: tensor([[-0.1444, -0.0277,  0.1492,  ...,  0.2944, -0.1876, -0.3982]]), time to record and predict: 0.1089792251586914\n",
      "tensor([[0.3576, 0.6424]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 54, sample: tensor([[-0.1656, -0.4105, -0.2658,  ...,  0.0717,  0.1474, -0.1112]]), time to record and predict: 0.13067412376403809\n",
      "tensor([[0.3538, 0.6462]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 55, sample: tensor([[-0.1583, -0.2907, -0.0485,  ...,  0.0657, -0.0292, -0.2137]]), time to record and predict: 0.12270736694335938\n",
      "tensor([[0.3416, 0.6584]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 56, sample: tensor([[-0.0784, -0.2660, -0.2657,  ..., -0.0927, -0.1881, -0.2194]]), time to record and predict: 0.1271812915802002\n",
      "tensor([[0.5273, 0.4727]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 57, sample: tensor([[-0.0085,  0.0734, -0.0429,  ..., -0.0941,  0.0624,  0.2001]]), time to record and predict: 0.014744043350219727\n",
      "tensor([[0.7770, 0.2230]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 58, sample: tensor([[ 0.1921,  0.2207,  0.1015,  ..., -0.0749, -0.0302, -0.1233]]), time to record and predict: 0.1137838363647461\n",
      "tensor([[0.9858, 0.0142]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 59, sample: tensor([[-0.2852,  0.0743,  0.4146,  ...,  0.2202,  0.1654,  0.1610]]), time to record and predict: 0.11793231964111328\n",
      "tensor([[0.9471, 0.0529]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 60, sample: tensor([[ 0.1026, -0.0728,  0.1883,  ...,  0.1424,  0.2701,  0.0580]]), time to record and predict: 0.13263273239135742\n",
      "tensor([[0.9692, 0.0308]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 61, sample: tensor([[ 0.0916,  0.1268, -0.0391,  ..., -0.1761, -0.2721, -0.2607]]), time to record and predict: 0.1237173080444336\n",
      "tensor([[0.9732, 0.0268]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 62, sample: tensor([[ 0.0887, -0.0058,  0.0568,  ..., -0.1588,  0.1350,  0.2435]]), time to record and predict: 0.020732879638671875\n",
      "tensor([[0.9838, 0.0162]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 63, sample: tensor([[-0.0141,  0.2562, -0.0363,  ...,  0.2676,  0.3413, -0.0168]]), time to record and predict: 0.1383652687072754\n",
      "tensor([[0.9493, 0.0507]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 64, sample: tensor([[-0.3851, -0.2035, -0.0129,  ...,  0.6329,  0.3963, -0.0278]]), time to record and predict: 0.12778520584106445\n",
      "tensor([[0.8457, 0.1543]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 65, sample: tensor([[-0.3457, -0.2357, -0.1381,  ...,  0.0970,  0.0095, -0.0866]]), time to record and predict: 0.016452789306640625\n",
      "tensor([[0.4041, 0.5959]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 66, sample: tensor([[-0.0817,  0.0537,  0.0458,  ...,  0.1035,  0.0407,  0.0992]]), time to record and predict: 0.1111764907836914\n",
      "tensor([[0.3070, 0.6930]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 67, sample: tensor([[ 0.1872,  0.0642, -0.0363,  ...,  0.0584,  0.1174, -0.0074]]), time to record and predict: 0.12433314323425293\n",
      "tensor([[0.3584, 0.6416]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 68, sample: tensor([[ 0.0562,  0.0921,  0.0147,  ...,  0.1964,  0.0302, -0.1447]]), time to record and predict: 0.12334275245666504\n",
      "tensor([[0.2449, 0.7551]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 69, sample: tensor([[ 0.1808,  0.1204,  0.0127,  ...,  0.0313, -0.0121, -0.0610]]), time to record and predict: 0.016460418701171875\n",
      "tensor([[0.0661, 0.9339]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 70, sample: tensor([[-0.1532, -0.1288, -0.0097,  ...,  0.1652,  0.2337, -0.0759]]), time to record and predict: 0.10867118835449219\n",
      "tensor([[0.0251, 0.9749]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 71, sample: tensor([[-0.1682,  0.0395,  0.1727,  ..., -0.0402,  0.0184,  0.0619]]), time to record and predict: 0.12537789344787598\n",
      "tensor([[0.0258, 0.9742]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 72, sample: tensor([[ 0.2197,  0.1144,  0.0551,  ..., -0.2041, -0.1650, -0.0761]]), time to record and predict: 0.12779879570007324\n",
      "tensor([[0.0819, 0.9181]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 73, sample: tensor([[-0.5506, -0.4533, -0.0184,  ..., -0.2897, -0.3628, -0.0490]]), time to record and predict: 0.12564826011657715\n",
      "tensor([[0.0521, 0.9479]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 74, sample: tensor([[-0.2035, -0.0777,  0.0686,  ...,  0.0446,  0.0276, -0.1438]]), time to record and predict: 0.018499135971069336\n",
      "tensor([[0.3499, 0.6501]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 75, sample: tensor([[-0.1578, -0.0891,  0.0232,  ...,  0.3739,  0.2209, -0.0674]]), time to record and predict: 0.10492181777954102\n",
      "tensor([[0.5028, 0.4972]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 76, sample: tensor([[ 0.1407,  0.1693,  0.3022,  ..., -0.6439, -0.6558, -0.4826]]), time to record and predict: 0.12746357917785645\n",
      "tensor([[0.0427, 0.9573]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 77, sample: tensor([[-0.0980, -0.1373, -0.0295,  ...,  0.4248,  0.1859,  0.2977]]), time to record and predict: 0.12549543380737305\n",
      "tensor([[0.0030, 0.9970]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 78, sample: tensor([[-0.0146,  0.1967,  0.2521,  ..., -0.0474, -0.0011,  0.0529]]), time to record and predict: 0.019173145294189453\n",
      "tensor([[0.0034, 0.9966]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 79, sample: tensor([[-0.0648, -0.1477, -0.0237,  ..., -0.0689,  0.0412,  0.1250]]), time to record and predict: 0.11200189590454102\n",
      "tensor([[0.0059, 0.9941]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 80, sample: tensor([[-0.0987,  0.1994,  0.0942,  ...,  0.1790,  0.1771,  0.0725]]), time to record and predict: 0.12266182899475098\n",
      "tensor([[0.0128, 0.9872]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 81, sample: tensor([[ 0.2394,  0.3225,  0.1422,  ...,  0.2660,  0.0515, -0.1146]]), time to record and predict: 0.12694549560546875\n",
      "tensor([[0.0101, 0.9899]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 82, sample: tensor([[-0.0475, -0.0099, -0.0499,  ..., -0.0730,  0.0648, -0.0793]]), time to record and predict: 0.12172818183898926\n",
      "tensor([[0.0116, 0.9884]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 83, sample: tensor([[ 0.1348,  0.1127,  0.0922,  ..., -0.0726,  0.0063, -0.1086]]), time to record and predict: 0.013256311416625977\n",
      "tensor([[0.0156, 0.9844]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 84, sample: tensor([[-0.1901, -0.0906, -0.0347,  ..., -0.0719, -0.3690, -0.3469]]), time to record and predict: 0.10934948921203613\n",
      "tensor([[0.0724, 0.9276]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 85, sample: tensor([[-0.0641,  0.0645,  0.2123,  ..., -0.4135, -0.1669,  0.0825]]), time to record and predict: 0.12884163856506348\n",
      "tensor([[0.4900, 0.5100]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 86, sample: tensor([[ 0.1516,  0.6603, -0.0882,  ..., -0.0521, -0.2905, -0.0698]]), time to record and predict: 0.12955832481384277\n",
      "tensor([[0.9313, 0.0687]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 87, sample: tensor([[ 0.1732, -0.1925, -0.1768,  ..., -0.4308, -0.1497,  0.1882]]), time to record and predict: 0.022394657135009766\n",
      "tensor([[0.9867, 0.0133]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 88, sample: tensor([[ 0.0288, -0.1153, -0.2001,  ..., -0.2236, -0.3488, -0.2336]]), time to record and predict: 0.13911867141723633\n",
      "tensor([[0.9968, 0.0032]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 89, sample: tensor([[ 0.3369,  0.4041, -0.0999,  ...,  0.2922,  0.4284,  0.2481]]), time to record and predict: 0.1207740306854248\n",
      "tensor([[0.9938, 0.0062]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 90, sample: tensor([[-0.1201, -0.3912, -0.3596,  ...,  0.1137,  0.2914,  0.2055]]), time to record and predict: 0.01427149772644043\n",
      "tensor([[0.9902, 0.0098]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 91, sample: tensor([[-0.0059,  0.1742,  0.3071,  ..., -0.7631, -1.0000, -1.0000]]), time to record and predict: 0.11695289611816406\n",
      "tensor([[0.9554, 0.0446]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 92, sample: tensor([[-0.3815, -0.4269, -0.0521,  ...,  0.3970,  0.3750, -0.1039]]), time to record and predict: 0.11841511726379395\n",
      "tensor([[0.8466, 0.1534]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 93, sample: tensor([[-0.3060, -0.3889, -0.1254,  ..., -0.2073,  0.1803,  0.1874]]), time to record and predict: 0.13216876983642578\n",
      "tensor([[0.9003, 0.0997]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 94, sample: tensor([[-0.0374,  0.1506,  0.1315,  ...,  0.2952, -0.2510, -0.5912]]), time to record and predict: 0.12099623680114746\n",
      "tensor([[0.8180, 0.1820]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 95, sample: tensor([[ 0.1619, -0.1251, -0.5083,  ...,  0.8819,  0.5206, -0.2611]]), time to record and predict: 0.01612997055053711\n",
      "tensor([[0.5606, 0.4394]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 96, sample: tensor([[ 0.3561,  0.2406, -0.1745,  ..., -0.4995, -0.2138, -0.0199]]), time to record and predict: 0.10846781730651855\n",
      "tensor([[0.5494, 0.4506]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 97, sample: tensor([[ 0.1903, -0.1216, -0.3663,  ...,  0.2514, -0.1733, -0.3936]]), time to record and predict: 0.13194966316223145\n",
      "tensor([[0.6330, 0.3670]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 98, sample: tensor([[ 0.0508,  0.1608,  0.0690,  ..., -0.0722,  0.1983,  0.2427]]), time to record and predict: 0.12157440185546875\n",
      "tensor([[0.6127, 0.3873]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 99, sample: tensor([[-0.1162, -0.3708, -0.2210,  ...,  0.3426, -0.0550, -0.3726]]), time to record and predict: 0.12465524673461914\n",
      "tensor([[0.8819, 0.1181]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 100, sample: tensor([[ 0.0293,  0.0009,  0.1635,  ..., -0.3742, -0.0988,  0.1882]]), time to record and predict: 0.015927791595458984\n",
      "tensor([[0.9233, 0.0767]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 101, sample: tensor([[-1.0000, -1.0000, -1.0000,  ..., -0.0972, -0.5065, -0.4158]]), time to record and predict: 0.11041808128356934\n",
      "tensor([[0.9605, 0.0395]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 102, sample: tensor([[-0.2462,  0.0477, -0.0710,  ...,  0.3842,  0.3613, -0.0183]]), time to record and predict: 0.13066720962524414\n",
      "tensor([[0.9785, 0.0215]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 103, sample: tensor([[-0.1381, -0.4214, -0.2788,  ..., -0.1125, -0.1927, -0.3307]]), time to record and predict: 0.12109494209289551\n",
      "tensor([[0.9445, 0.0555]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 104, sample: tensor([[-0.4649,  0.0918,  0.4885,  ...,  0.0715, -0.1523, -0.3207]]), time to record and predict: 0.016386032104492188\n",
      "tensor([[0.8372, 0.1628]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 105, sample: tensor([[-0.7707, -0.5178,  0.3095,  ..., -0.1981,  0.0239, -0.1147]]), time to record and predict: 0.10750269889831543\n",
      "tensor([[0.8911, 0.1089]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 106, sample: tensor([[ 0.0883,  0.0935, -0.0229,  ...,  0.0286,  0.0428,  0.0928]]), time to record and predict: 0.1260695457458496\n",
      "tensor([[0.7360, 0.2640]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 107, sample: tensor([[-0.0620,  0.2932,  0.3125,  ...,  0.1227,  0.0471,  0.0156]]), time to record and predict: 0.12827062606811523\n",
      "tensor([[0.5181, 0.4819]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 108, sample: tensor([[-0.1909, -0.2037,  0.1382,  ..., -0.2364, -0.2173,  0.1822]]), time to record and predict: 0.12575578689575195\n",
      "tensor([[0.3342, 0.6658]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 109, sample: tensor([[-0.3756, -0.2017,  0.3645,  ...,  0.0546,  0.0056, -0.0522]]), time to record and predict: 0.01633596420288086\n",
      "tensor([[0.1714, 0.8286]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 110, sample: tensor([[ 0.4309,  0.1059, -0.3711,  ...,  0.2408,  0.6220,  0.7190]]), time to record and predict: 0.1103208065032959\n",
      "tensor([[0.0679, 0.9321]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 111, sample: tensor([[ 0.0931,  0.1155, -0.2897,  ...,  0.0525, -0.0681, -0.1211]]), time to record and predict: 0.1236419677734375\n",
      "tensor([[0.0279, 0.9721]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 112, sample: tensor([[-0.4858, -0.3264,  0.0961,  ...,  0.0284, -0.1606, -0.2123]]), time to record and predict: 0.13393735885620117\n",
      "tensor([[0.1791, 0.8209]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 113, sample: tensor([[-0.1668,  0.0992, -0.0416,  ...,  0.0815,  0.2323, -0.2856]]), time to record and predict: 0.021564960479736328\n",
      "tensor([[0.3060, 0.6940]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 114, sample: tensor([[-0.1855,  0.0199,  0.1232,  ..., -0.0189,  0.0500,  0.0605]]), time to record and predict: 0.14026498794555664\n",
      "tensor([[0.3713, 0.6287]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 115, sample: tensor([[-0.1656,  0.3331,  0.2987,  ..., -0.0337, -0.1606, -0.0707]]), time to record and predict: 0.12585139274597168\n",
      "tensor([[0.5747, 0.4253]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 116, sample: tensor([[ 0.0689,  0.0695,  0.0657,  ..., -0.0482,  0.0526,  0.0062]]), time to record and predict: 0.01840519905090332\n",
      "tensor([[0.3634, 0.6366]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 117, sample: tensor([[ 0.2344,  0.1644,  0.1638,  ...,  0.1305,  0.0444, -0.0917]]), time to record and predict: 0.1066434383392334\n",
      "tensor([[0.2522, 0.7478]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 118, sample: tensor([[ 0.2339,  0.0066, -0.1762,  ..., -0.3185,  0.1050, -0.0348]]), time to record and predict: 0.12175202369689941\n",
      "tensor([[0.2288, 0.7712]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 119, sample: tensor([[-0.1314, -0.1288, -0.0701,  ...,  0.0754, -0.0491, -0.0480]]), time to record and predict: 0.1278069019317627\n",
      "tensor([[0.6469, 0.3531]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 120, sample: tensor([[ 0.6754,  0.5514,  0.6040,  ..., -0.0961, -0.3064,  0.0155]]), time to record and predict: 0.12965655326843262\n",
      "tensor([[0.8824, 0.1176]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 121, sample: tensor([[-0.0516, -0.0437,  0.0315,  ..., -0.0310, -0.1902,  0.0508]]), time to record and predict: 0.01572251319885254\n",
      "tensor([[0.9232, 0.0768]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import torch\n",
    "import torchaudio\n",
    "import time\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "NUM_OF_CHUNKS = 10\n",
    "CHUNK = int(RATE/NUM_OF_CHUNKS)\n",
    "RECORD_SECONDS = 1\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "def process_sample(sample):\n",
    "    sample = torch.clamp(sample, -1.0, 1.0)\n",
    "    SR = 16000\n",
    "    hop_length=160\n",
    "    win_length=480\n",
    "    n_fft=512\n",
    "    n_mels=40\n",
    "    feature = LogMel(\n",
    "                device,\n",
    "                sample_rate=SR,\n",
    "                hop_length=hop_length,\n",
    "                win_length=win_length,\n",
    "                n_fft=n_fft,\n",
    "                n_mels=n_mels,\n",
    "            )\n",
    "    sample = feature(sample)  \n",
    "    sample = spec_augment(sample)\n",
    "    return sample\n",
    "\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Recording...\")\n",
    "\n",
    "sample_window = int(RATE * RECORD_SECONDS) # How much samples in recorded audio\n",
    "chunks_num = int(sample_window/CHUNK) # How much chunks in recorder audio\n",
    "\n",
    "sample = torch.zeros(1, sample_window) #.to(device)\n",
    "i = 0\n",
    "try:\n",
    "    while True:\n",
    "        i+=1\n",
    "        start_time = time.time()\n",
    "\n",
    "        data = stream.read(CHUNK) # Считываем чанк аудиосигнала с микрофона\n",
    "        audio_tensor = torch.from_numpy(np.frombuffer(data, dtype=np.int16) / 32767.0) # Преобразуем в тензор\n",
    "        sample[0, 0:(chunks_num - 1)*CHUNK] = sample[0, CHUNK:chunks_num*CHUNK].clone() # Передвигаем значения сэмпла от второго до последнего чанка в диапазон от первого до предпоследнего чанка\n",
    "        # print(f\"audio_tensor shape: {audio_tensor.shape}, sample shape: {sample.shape}, sample[0, chunk] shape: {sample[0, CHUNK:chunks_num*CHUNK].shape}\")\n",
    "        sample[0, (chunks_num - 1)*CHUNK:chunks_num*CHUNK] = audio_tensor\n",
    "\n",
    "        # Process the audio tensor with feature extraction and classification\n",
    "        sample_processed = process_sample(sample)\n",
    "        sample_processed = sample_processed.to(device)\n",
    "\n",
    "        outputs = model(sample_processed.unsqueeze(0))\n",
    "        predictions = F.softmax(outputs)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Iteration: {i}, sample: {sample}, time to record and predict: {end_time-start_time}\")\n",
    "        print(predictions)\n",
    "\n",
    "        if i >= NUM_OF_CHUNKS:\n",
    "            if predictions[0][1].item() > 0.99:\n",
    "                print(\"Keyword\")\n",
    "                #break\n",
    "            else:\n",
    "                print(\"Filler\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запись и распознавание в потоковом режиме с подавлением шумов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tapok/miniconda3/envs/bcresnet/lib/python3.6/site-packages/ipykernel_launcher.py:63: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, sample: tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.2519, -0.1958, -0.0604]]), time to record and predict: 0.21543359756469727\n",
      "tensor([[0.1037, 0.8963]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 2, sample: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0353,  0.0142, -0.0161]]), time to record and predict: 0.06184816360473633\n",
      "tensor([[0.0339, 0.9661]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 3, sample: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.2931, 0.2058, 0.0516]]), time to record and predict: 0.19604992866516113\n",
      "tensor([[0.0197, 0.9803]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 4, sample: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0670, -0.0308, -0.1085]]), time to record and predict: 0.049411773681640625\n",
      "tensor([[0.7324, 0.2676]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 5, sample: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0592,  0.0619, -0.0111]]), time to record and predict: 0.05950045585632324\n",
      "tensor([[0.9860, 0.0140]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 6, sample: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0625, 0.2709, 0.0504]]), time to record and predict: 0.16534900665283203\n",
      "tensor([[0.9941, 0.0059]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 7, sample: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0099, -0.2327,  0.0689]]), time to record and predict: 0.0497746467590332\n",
      "tensor([[0.9828, 0.0172]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 8, sample: tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.2940, -0.0384,  0.0889]]), time to record and predict: 0.051642417907714844\n",
      "tensor([[0.9690, 0.0310]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 9, sample: tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.2127,  0.0666, -0.1818]]), time to record and predict: 0.15471458435058594\n",
      "tensor([[0.9768, 0.0232]], grad_fn=<SoftmaxBackward>)\n",
      "Iteration: 10, sample: tensor([[-0.1322, -0.0340,  0.0779,  ...,  0.0107, -0.1352, -0.0938]]), time to record and predict: 0.052007436752319336\n",
      "tensor([[0.8053, 0.1947]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 11, sample: tensor([[-0.2034, -0.1316, -0.0559,  ...,  0.1836,  0.1088,  0.1091]]), time to record and predict: 0.15613508224487305\n",
      "tensor([[0.9088, 0.0912]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 12, sample: tensor([[-0.1012, -0.2591, -0.2834,  ..., -0.0454, -0.2738, -0.3498]]), time to record and predict: 0.05516552925109863\n",
      "tensor([[0.9348, 0.0652]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 13, sample: tensor([[ 0.1203,  0.1382,  0.1332,  ..., -0.0792, -0.0740, -0.1685]]), time to record and predict: 0.15126442909240723\n",
      "tensor([[0.9663, 0.0337]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 14, sample: tensor([[-0.1754, -0.1069,  0.1861,  ..., -0.2318, -0.1025,  0.1219]]), time to record and predict: 0.054293155670166016\n",
      "tensor([[0.9648, 0.0352]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 15, sample: tensor([[-0.0904, -0.0010, -0.0257,  ...,  0.0159, -0.0253, -0.0548]]), time to record and predict: 0.17273521423339844\n",
      "tensor([[0.9343, 0.0657]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 16, sample: tensor([[ 0.0301, -0.0463,  0.0021,  ..., -0.0385, -0.1699, -0.1581]]), time to record and predict: 0.0519561767578125\n",
      "tensor([[0.9699, 0.0301]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 17, sample: tensor([[ 0.0038, -0.2370,  0.0955,  ..., -0.2455, -0.1983, -0.1949]]), time to record and predict: 0.04942965507507324\n",
      "tensor([[0.9652, 0.0348]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 18, sample: tensor([[ 0.0769, -0.0130, -0.1281,  ..., -0.1145, -0.1378, -0.1049]]), time to record and predict: 0.1812889575958252\n",
      "tensor([[0.8111, 0.1889]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 19, sample: tensor([[-0.1044,  0.0083,  0.0390,  ...,  0.3187,  0.3780, -0.4191]]), time to record and predict: 0.05177497863769531\n",
      "tensor([[0.9329, 0.0671]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 20, sample: tensor([[-0.0129,  0.1041,  0.1246,  ...,  0.0630, -0.1249, -0.1013]]), time to record and predict: 0.05038762092590332\n",
      "tensor([[0.9368, 0.0632]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 21, sample: tensor([[ 0.2034,  0.3539,  0.3485,  ..., -0.2268, -0.1225, -0.0929]]), time to record and predict: 0.15348410606384277\n",
      "tensor([[0.9294, 0.0706]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 22, sample: tensor([[-0.2554, -0.0701,  0.1151,  ..., -0.1483, -0.1161, -0.1789]]), time to record and predict: 0.05303525924682617\n",
      "tensor([[0.9404, 0.0596]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 23, sample: tensor([[-0.2034, -0.1393, -0.1451,  ..., -0.0845,  0.0272,  0.0121]]), time to record and predict: 0.15251660346984863\n",
      "tensor([[0.8099, 0.1901]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 24, sample: tensor([[ 0.1218,  0.1494,  0.0239,  ..., -0.1731, -0.2602, -0.1806]]), time to record and predict: 0.05294632911682129\n",
      "tensor([[0.8308, 0.1692]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 25, sample: tensor([[ 0.0120,  0.0754, -0.0232,  ..., -1.0000, -1.0000, -0.5447]]), time to record and predict: 0.161787748336792\n",
      "tensor([[0.3520, 0.6480]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 26, sample: tensor([[ 0.0363,  0.0948, -0.0821,  ...,  0.1913,  0.1975,  0.2017]]), time to record and predict: 0.05201244354248047\n",
      "tensor([[0.0030, 0.9970]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 27, sample: tensor([[-0.0920,  0.0041, -0.0480,  ...,  0.0337,  0.2232,  0.2293]]), time to record and predict: 0.1559293270111084\n",
      "tensor([[0.0015, 0.9985]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 28, sample: tensor([[ 0.0766,  0.1328, -0.0400,  ..., -0.1202, -0.2273, -0.1289]]), time to record and predict: 0.053719282150268555\n",
      "tensor([[0.0025, 0.9975]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 29, sample: tensor([[-0.1852, -0.1516,  0.0548,  ..., -0.2362, -0.1817, -0.0652]]), time to record and predict: 0.15036940574645996\n",
      "tensor([[0.0024, 0.9976]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 30, sample: tensor([[-0.2167, -0.0879,  0.2042,  ...,  0.0107, -0.0728, -0.0663]]), time to record and predict: 0.05296969413757324\n",
      "tensor([[0.0012, 0.9988]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 31, sample: tensor([[-0.0016,  0.0890, -0.0010,  ...,  0.1010, -0.0496, -0.3029]]), time to record and predict: 0.04691815376281738\n",
      "tensor([[0.0032, 0.9968]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 32, sample: tensor([[-0.0074,  0.2380,  0.0905,  ..., -0.5232,  0.0044,  0.2533]]), time to record and predict: 0.17629742622375488\n",
      "tensor([[0.0018, 0.9982]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 33, sample: tensor([[-0.1113, -0.2356, -0.1950,  ..., -0.0370, -0.0040, -0.0565]]), time to record and predict: 0.04992103576660156\n",
      "tensor([[0.0709, 0.9291]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 34, sample: tensor([[-0.0624, -0.0598, -0.0411,  ..., -0.1138, -0.0496,  0.0977]]), time to record and predict: 0.04820871353149414\n",
      "tensor([[0.3505, 0.6495]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 35, sample: tensor([[-0.1154,  0.2957,  0.6612,  ...,  0.3273,  0.3731,  0.0482]]), time to record and predict: 0.19844436645507812\n",
      "tensor([[0.5988, 0.4012]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 36, sample: tensor([[ 0.0342,  0.0111,  0.0574,  ..., -0.1322, -0.1054, -0.0501]]), time to record and predict: 0.05068635940551758\n",
      "tensor([[0.9644, 0.0356]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 37, sample: tensor([[-0.0568, -0.2614, -0.3924,  ..., -0.2549, -0.0041,  0.1309]]), time to record and predict: 0.04745912551879883\n",
      "tensor([[0.9693, 0.0307]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 38, sample: tensor([[ 0.0013,  0.1580, -0.0011,  ..., -0.1566, -0.1372, -0.0865]]), time to record and predict: 0.17514562606811523\n",
      "tensor([[0.9200, 0.0800]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 39, sample: tensor([[ 0.0864,  0.0178,  0.0919,  ...,  0.0177, -0.4456, -0.1562]]), time to record and predict: 0.05018210411071777\n",
      "tensor([[0.9866, 0.0134]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 40, sample: tensor([[ 0.1216,  0.1087, -0.0232,  ...,  0.4471, -0.0869, -0.4107]]), time to record and predict: 0.1524965763092041\n",
      "tensor([[0.9905, 0.0095]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 41, sample: tensor([[-0.2680, -0.1361, -0.0275,  ...,  0.0023,  0.1777,  0.0573]]), time to record and predict: 0.06346297264099121\n",
      "tensor([[0.9659, 0.0341]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 42, sample: tensor([[ 0.0045,  0.2228, -0.0545,  ..., -0.0966, -0.1223, -0.1130]]), time to record and predict: 0.1463484764099121\n",
      "tensor([[0.9797, 0.0203]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 43, sample: tensor([[-0.0342, -0.1302, -0.1936,  ..., -0.0803, -0.0160, -0.0829]]), time to record and predict: 0.051775217056274414\n",
      "tensor([[0.9639, 0.0361]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 44, sample: tensor([[ 0.0886, -0.0197, -0.2399,  ...,  0.0357, -0.0031, -0.1710]]), time to record and predict: 0.17926955223083496\n",
      "tensor([[0.9130, 0.0870]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 45, sample: tensor([[-0.0406, -0.3145, -0.2985,  ..., -0.1843, -0.1104,  0.0915]]), time to record and predict: 0.0489959716796875\n",
      "tensor([[0.9315, 0.0685]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 46, sample: tensor([[ 0.1309,  0.1823,  0.0824,  ..., -0.2271, -0.1200, -0.2513]]), time to record and predict: 0.04863119125366211\n",
      "tensor([[0.8554, 0.1446]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 47, sample: tensor([[ 0.0309, -0.0477, -0.0860,  ...,  0.1584,  0.0414, -0.2391]]), time to record and predict: 0.19799184799194336\n",
      "tensor([[0.8493, 0.1507]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 48, sample: tensor([[-0.0494, -0.0716, -0.0579,  ...,  0.1970, -0.1265, -0.1473]]), time to record and predict: 0.04937863349914551\n",
      "tensor([[0.7347, 0.2653]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 49, sample: tensor([[ 0.1817, -0.0185,  0.0840,  ...,  0.1893,  0.1844,  0.2051]]), time to record and predict: 0.04886889457702637\n",
      "tensor([[0.6471, 0.3529]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 50, sample: tensor([[-0.2889, -0.1724, -0.0727,  ..., -0.1588, -0.1629,  0.0906]]), time to record and predict: 0.198960542678833\n",
      "tensor([[0.6775, 0.3225]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 51, sample: tensor([[-0.0768, -0.2080, -0.2217,  ..., -0.1725,  0.0254,  0.2832]]), time to record and predict: 0.050446510314941406\n",
      "tensor([[0.4351, 0.5649]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 52, sample: tensor([[ 0.0461, -0.0429, -0.1762,  ..., -0.4290, -0.3815, -0.0169]]), time to record and predict: 0.047747135162353516\n",
      "tensor([[0.1364, 0.8636]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 53, sample: tensor([[ 0.0167,  0.0789,  0.0201,  ..., -0.2297, -0.2199, -0.1072]]), time to record and predict: 0.19408917427062988\n",
      "tensor([[0.7187, 0.2813]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 54, sample: tensor([[-0.0560,  0.0418,  0.0324,  ...,  0.1362, -0.0105, -0.1415]]), time to record and predict: 0.05055737495422363\n",
      "tensor([[0.4821, 0.5179]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 55, sample: tensor([[-0.1556, -0.0425,  0.0240,  ...,  0.2981,  0.1228, -0.0488]]), time to record and predict: 0.04889559745788574\n",
      "tensor([[0.5995, 0.4005]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 56, sample: tensor([[-0.2477, -0.2821, -0.0591,  ..., -0.3579, -0.2492, -0.0757]]), time to record and predict: 0.18046021461486816\n",
      "tensor([[0.5428, 0.4572]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 57, sample: tensor([[-0.0636,  0.3413,  0.5244,  ..., -0.1388, -0.0987,  0.1182]]), time to record and predict: 0.05402779579162598\n",
      "tensor([[0.8428, 0.1572]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 58, sample: tensor([[-0.0058,  0.0859,  0.1777,  ..., -0.0325, -0.1320, -0.2017]]), time to record and predict: 0.048316001892089844\n",
      "tensor([[0.9511, 0.0489]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 59, sample: tensor([[ 0.1707,  0.0493,  0.0495,  ...,  0.1369, -0.1733, -0.2782]]), time to record and predict: 0.14838695526123047\n",
      "tensor([[0.9523, 0.0477]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 60, sample: tensor([[0.2116, 0.0747, 0.0794,  ..., 0.0748, 0.0044, 0.0827]]), time to record and predict: 0.04844236373901367\n",
      "tensor([[0.9801, 0.0199]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 61, sample: tensor([[ 0.2159,  0.1328, -0.0297,  ..., -0.0165, -0.0302,  0.1037]]), time to record and predict: 0.16335725784301758\n",
      "tensor([[0.9840, 0.0160]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 62, sample: tensor([[-0.0763, -0.0022,  0.2102,  ..., -0.0602, -0.0956,  0.0042]]), time to record and predict: 0.059282541275024414\n",
      "tensor([[0.9786, 0.0214]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 63, sample: tensor([[ 0.0045,  0.0607,  0.0780,  ..., -0.3664, -0.1490,  0.1700]]), time to record and predict: 0.1427631378173828\n",
      "tensor([[0.9746, 0.0254]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 64, sample: tensor([[-0.2321, -0.0909,  0.1688,  ..., -0.0813, -0.1970, -0.0646]]), time to record and predict: 0.05300498008728027\n",
      "tensor([[0.9638, 0.0362]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 65, sample: tensor([[ 0.1859,  0.2769,  0.1538,  ..., -0.3383, -0.3728, -0.0309]]), time to record and predict: 0.15644001960754395\n",
      "tensor([[0.0827, 0.9173]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 66, sample: tensor([[ 0.0498,  0.0448, -0.0077,  ...,  0.1109,  0.1483,  0.1043]]), time to record and predict: 0.05643033981323242\n",
      "tensor([[0.0030, 0.9970]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 67, sample: tensor([[ 0.1495,  0.1006, -0.0471,  ..., -0.0576, -0.0602,  0.1174]]), time to record and predict: 0.15698003768920898\n",
      "tensor([[0.0019, 0.9981]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 68, sample: tensor([[-0.1311,  0.0494,  0.0224,  ...,  0.1014,  0.1090,  0.0587]]), time to record and predict: 0.056885719299316406\n",
      "tensor([[9.1345e-04, 9.9909e-01]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 69, sample: tensor([[-0.1065,  0.0912,  0.2730,  ...,  0.0274,  0.1881,  0.0227]]), time to record and predict: 0.049852609634399414\n",
      "tensor([[0.0011, 0.9989]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 70, sample: tensor([[-0.1696, -0.1107,  0.2284,  ..., -0.1928, -0.1434, -0.1561]]), time to record and predict: 0.1455221176147461\n",
      "tensor([[4.3536e-04, 9.9956e-01]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 71, sample: tensor([[ 0.1229, -0.1187, -0.1586,  ...,  0.1758,  0.1988,  0.1746]]), time to record and predict: 0.050743818283081055\n",
      "tensor([[0.0069, 0.9931]], grad_fn=<SoftmaxBackward>)\n",
      "Keyword\n",
      "Iteration: 72, sample: tensor([[-0.0267, -0.0825,  0.0324,  ...,  0.0684, -0.0233, -0.1741]]), time to record and predict: 0.1563887596130371\n",
      "tensor([[0.0316, 0.9684]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 73, sample: tensor([[ 0.1701, -0.0125, -0.1542,  ..., -0.0950,  0.3309,  0.4085]]), time to record and predict: 0.05543398857116699\n",
      "tensor([[0.2271, 0.7729]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 74, sample: tensor([[ 0.0414,  0.1194,  0.0408,  ...,  0.1898,  0.0297, -0.0760]]), time to record and predict: 0.15384912490844727\n",
      "tensor([[0.3863, 0.6137]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 75, sample: tensor([[ 0.6222,  0.2523, -0.4024,  ..., -0.0406, -0.0518, -0.2453]]), time to record and predict: 0.0525205135345459\n",
      "tensor([[0.6051, 0.3949]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 76, sample: tensor([[0.0520, 0.1514, 0.2485,  ..., 0.0784, 0.0586, 0.1164]]), time to record and predict: 0.16452574729919434\n",
      "tensor([[0.9909, 0.0091]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 77, sample: tensor([[-0.0725, -0.0933, -0.0607,  ...,  0.0971,  0.0629, -0.1358]]), time to record and predict: 0.05355668067932129\n",
      "tensor([[0.9358, 0.0642]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 78, sample: tensor([[ 0.0495, -0.0173, -0.0795,  ...,  0.4308,  0.3557,  0.2610]]), time to record and predict: 0.05252432823181152\n",
      "tensor([[0.8148, 0.1852]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 79, sample: tensor([[-0.1160, -0.1715, -0.0097,  ...,  0.1693,  0.0205, -0.0984]]), time to record and predict: 0.1852092742919922\n",
      "tensor([[0.9818, 0.0182]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 80, sample: tensor([[ 0.0611,  0.1562,  0.0830,  ...,  0.0223, -0.0393, -0.0605]]), time to record and predict: 0.0541691780090332\n",
      "tensor([[0.9826, 0.0174]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 81, sample: tensor([[ 0.0593, -0.0211, -0.0338,  ...,  0.1034,  0.2271,  0.1953]]), time to record and predict: 0.058684349060058594\n",
      "tensor([[0.9865, 0.0135]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 82, sample: tensor([[-0.2142, -0.1796, -0.0733,  ..., -0.0913, -0.0255, -0.0005]]), time to record and predict: 0.2009110450744629\n",
      "tensor([[0.9525, 0.0475]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 83, sample: tensor([[ 0.1493, -0.0800, -0.2027,  ..., -0.0271, -0.1659, -0.0758]]), time to record and predict: 0.04994916915893555\n",
      "tensor([[0.9633, 0.0367]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 84, sample: tensor([[-0.0889, -0.1078, -0.0293,  ..., -0.2039, -0.2100, -0.0613]]), time to record and predict: 0.058339834213256836\n",
      "tensor([[0.9477, 0.0523]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 85, sample: tensor([[-0.2845, -0.1030, -0.0621,  ...,  0.0873,  0.0906, -0.1507]]), time to record and predict: 0.17581844329833984\n",
      "tensor([[0.9903, 0.0097]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 86, sample: tensor([[ 0.1010, -0.0028, -0.0135,  ...,  0.0515,  0.1675,  0.1885]]), time to record and predict: 0.06642889976501465\n",
      "tensor([[0.9919, 0.0081]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 87, sample: tensor([[-0.0661,  0.2155,  0.3890,  ..., -0.0123,  0.0269,  0.0396]]), time to record and predict: 0.0645742416381836\n",
      "tensor([[0.9817, 0.0183]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 88, sample: tensor([[ 0.1267, -0.1796, -0.2185,  ..., -0.1131, -0.1089, -0.1043]]), time to record and predict: 0.1685199737548828\n",
      "tensor([[0.9012, 0.0988]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 89, sample: tensor([[ 0.0159,  0.1752,  0.2514,  ..., -0.0656, -0.0679, -0.0639]]), time to record and predict: 0.06501388549804688\n",
      "tensor([[0.9365, 0.0635]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 90, sample: tensor([[0.0270, 0.0418, 0.0338,  ..., 0.0518, 0.0506, 0.0463]]), time to record and predict: 0.06867671012878418\n",
      "tensor([[0.9170, 0.0830]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 91, sample: tensor([[ 0.1453, -0.0472, -0.2313,  ..., -0.0097, -0.0064, -0.0069]]), time to record and predict: 0.06551694869995117\n",
      "tensor([[0.9026, 0.0974]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 92, sample: tensor([[-0.0186, -0.1366, -0.2337,  ...,  0.0397,  0.0416,  0.0492]]), time to record and predict: 0.15704035758972168\n",
      "tensor([[0.8083, 0.1917]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 93, sample: tensor([[ 0.0667,  0.1415,  0.3129,  ..., -0.0776, -0.0811, -0.0815]]), time to record and predict: 0.06211686134338379\n",
      "tensor([[0.9505, 0.0495]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 94, sample: tensor([[ 0.0327, -0.0254, -0.0898,  ..., -0.0072, -0.0042, -0.0026]]), time to record and predict: 0.1537611484527588\n",
      "tensor([[0.9240, 0.0760]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 95, sample: tensor([[-0.1607, -0.1801,  0.0728,  ..., -0.0890, -0.0827, -0.0802]]), time to record and predict: 0.05478382110595703\n",
      "tensor([[0.8414, 0.1586]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 96, sample: tensor([[ 0.1116,  0.1155, -0.0009,  ..., -0.0685, -0.0689, -0.0656]]), time to record and predict: 0.1422872543334961\n",
      "tensor([[0.9615, 0.0385]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n",
      "Iteration: 97, sample: tensor([[ 0.0058, -0.0254, -0.0198,  ..., -0.0780, -0.0833, -0.0830]]), time to record and predict: 0.05166339874267578\n",
      "tensor([[0.9747, 0.0253]], grad_fn=<SoftmaxBackward>)\n",
      "Filler\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import torch\n",
    "import torchaudio\n",
    "import time\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "NUM_OF_CHUNKS = 10\n",
    "CHUNK = int(RATE/NUM_OF_CHUNKS)\n",
    "RECORD_SECONDS = 1\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "def process_sample(sample):\n",
    "    sample = torch.clamp(sample, -1.0, 1.0)\n",
    "    SR = 16000\n",
    "    hop_length=160\n",
    "    win_length=480\n",
    "    n_fft=512\n",
    "    n_mels=40\n",
    "    feature = LogMel(\n",
    "                device,\n",
    "                sample_rate=SR,\n",
    "                hop_length=hop_length,\n",
    "                win_length=win_length,\n",
    "                n_fft=n_fft,\n",
    "                n_mels=n_mels,\n",
    "            )\n",
    "    sample = feature(sample)  \n",
    "    sample = spec_augment(sample)\n",
    "    return sample\n",
    "\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Recording...\")\n",
    "\n",
    "sample_window = int(RATE * RECORD_SECONDS) # How much samples in recorded audio\n",
    "chunks_num = int(sample_window/CHUNK) # How much chunks in recorder audio\n",
    "\n",
    "sample = torch.zeros(1, sample_window)\n",
    "i = 0\n",
    "try:\n",
    "    while True:\n",
    "        i+=1\n",
    "        start_time = time.time()\n",
    "\n",
    "        data = stream.read(CHUNK) # Считываем чанк аудиосигнала с микрофона\n",
    "        audio_tensor = torch.from_numpy(np.frombuffer(data, dtype=np.int16) / 32767.0) # Преобразуем в тензор\n",
    "\n",
    "        sample[0, 0:(chunks_num - 1)*CHUNK] = sample[0, CHUNK:chunks_num*CHUNK].clone() # Передвигаем значения сэмпла от второго до последнего чанка в диапазон от первого до предпоследнего чанка\n",
    "        sample[0, (chunks_num - 1)*CHUNK:chunks_num*CHUNK] = audio_tensor\n",
    "\n",
    "        nr_sample = torch.tensor(nr.reduce_noise(y=sample, sr=RATE, stationary=True))\n",
    "\n",
    "        # Process the audio tensor with feature extraction and classification\n",
    "        sample_processed = process_sample(nr_sample)\n",
    "        sample_processed = sample_processed.to(device)\n",
    "\n",
    "        outputs = model(sample_processed.unsqueeze(0))\n",
    "        predictions = F.softmax(outputs)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Iteration: {i}, sample: {sample}, time to record and predict: {end_time-start_time}\")\n",
    "        print(predictions)\n",
    "\n",
    "        if i >= NUM_OF_CHUNKS:\n",
    "            if predictions[0][1].item() > 0.99:\n",
    "                print(\"Keyword\")\n",
    "                #break\n",
    "            else:\n",
    "                print(\"Filler\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 1.0\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Recording...\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Finished recording.\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "waveFile = wave.open(WAVE_OUTPUT_FILENAME, \"wb\")\n",
    "waveFile.setnchannels(CHANNELS)\n",
    "waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "waveFile.setframerate(RATE)\n",
    "waveFile.writeframes(b\"\".join(frames))\n",
    "waveFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio.get_sample_size(FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
